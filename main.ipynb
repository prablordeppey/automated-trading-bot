{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRAPHERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_signals(df, source_col, signal_col, figsize=(10, 6)):\n",
    "    \"\"\"\n",
    "    Plot the price data along with buy/sell/hold signals.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing the data.\n",
    "        source_col (str): Name of the source column (e.g., close prices) in the DataFrame.\n",
    "        signal_col (list): List of signal column names in the DataFrame.\n",
    "        figsize (tuple): Figure size (width, height).\n",
    "    \"\"\"\n",
    "    # Plot the price data\n",
    "    ax = df[list(set(df.columns) - set(signal_col))].plot(figsize=figsize, label=\"Price\")\n",
    "    \n",
    "    # Get the indices where each signal occurs\n",
    "    for col in signal_col:\n",
    "        buy_indices = df.index[df[col] == 1]\n",
    "        sell_indices = df.index[df[col] == -1]\n",
    "        hold_indices = df.index[df[col] == 999]\n",
    "\n",
    "        # Plot buy signals (signal = 1) as green triangles\n",
    "        if len(buy_indices) > 0:\n",
    "            ax.scatter(buy_indices, df.loc[buy_indices, source_col], color='green', marker='^', label=f'Buy Signal - {col}', s=80)\n",
    "\n",
    "        # Plot sell signals (signal = -1) as red triangles\n",
    "        if len(sell_indices) > 0:\n",
    "            ax.scatter(sell_indices, df.loc[sell_indices, source_col], color='red', marker='v', label=f'Sell Signal - {col}', s=80)\n",
    "\n",
    "        # Plot hold signals (signal = 0) as blue circles\n",
    "        if len(hold_indices) > 0:\n",
    "            ax.scatter(hold_indices, df.loc[hold_indices, source_col], color='blue', marker='o', label=f'Hold Signal - {col}', s=80)\n",
    "\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.title(\"Price with Buy/Sell/Hold Signals\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIGNAL METHODS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_target_variables(open_series, high_series, low_series, close_series, volume_series):\n",
    "    \"\"\"\n",
    "    Compute the target variables indicating bullish or bearish candle, percentage change in prices,\n",
    "    and additional targets based on price movement and volume.\n",
    "    \n",
    "    Args:\n",
    "        open_series (pd.Series): Series containing the opening prices.\n",
    "        high_series (pd.Series): Series containing the highest prices.\n",
    "        low_series (pd.Series): Series containing the lowest prices.\n",
    "        close_series (pd.Series): Series containing the closing prices.\n",
    "        volume_series (pd.Series): Series containing the volume data.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with the target variables and percentage changes.\n",
    "    \"\"\"\n",
    "    # Create a new DataFrame to store the computed features\n",
    "    new_df = pd.DataFrame(index=open_series.index)\n",
    "    \n",
    "    # Calculate percentage change for each price (current day)\n",
    "    new_df['open_change_intermediate'] = open_series.pct_change()\n",
    "    new_df['high_change_intermediate'] = high_series.pct_change()\n",
    "    new_df['low_change_intermediate'] = low_series.pct_change()\n",
    "    new_df['close_change_intermediate'] = close_series.pct_change()\n",
    "    \n",
    "    # Determine bullish or bearish candle (current day)\n",
    "    new_df['close_bullish_bearish_signal'] = np.where(close_series > open_series, 1, -1)\n",
    "    \n",
    "    # Compute overall change in price (drop) (current day)\n",
    "    new_df['price_change_intermediate'] = close_series - close_series.shift(1)\n",
    "    \n",
    "    # Calculate percentage change for each price (previous day)\n",
    "    new_df['prev_open_change_intermediate'] = open_series.shift(1).pct_change()\n",
    "    new_df['prev_high_change_intermediate'] = high_series.shift(1).pct_change()\n",
    "    new_df['prev_low_change_intermediate'] = low_series.shift(1).pct_change()\n",
    "    new_df['prev_close_change_intermediate'] = close_series.shift(1).pct_change()\n",
    "    \n",
    "    # Determine if today's closing price is higher than yesterday's price and recorded higher highs and higher lows\n",
    "    new_df['price_increase_and_higher_highs_lows_signal'] = np.where(\n",
    "        (close_series > close_series.shift(1)) &\n",
    "        (high_series > high_series.shift(1)) &\n",
    "        (low_series > low_series.shift(1)),\n",
    "        1, -1\n",
    "    )\n",
    "    \n",
    "    # Compute percentage change in volume\n",
    "    new_df['volume_change_intermediate'] = volume_series.pct_change()\n",
    "    new_df['volume_bullish_bearish_signal'] = np.where(volume_series > volume_series.shift(1), 1, -1)\n",
    "\n",
    "    \n",
    "    return new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_k_majority(src: pd.Series, k: int):\n",
    "    \"\"\"\n",
    "    Calculate the majority class based on the count of up candles in the past k rows.\n",
    "    \n",
    "    Args:\n",
    "        src (pd.Series): Series containing the source data (e.g., close prices).\n",
    "        k (int): Number of past rows to consider for majority calculation.\n",
    "    \n",
    "    Returns:\n",
    "        pd.Series: A Series containing the majority class for each element in the source data.\n",
    "    \"\"\"\n",
    "    # Calculate the target label indicating whether each candle is an up or down candle\n",
    "    up_down = (src.diff() > 0).astype(int)\n",
    "\n",
    "    # Use a rolling window to count the number of up candles in the past k rows\n",
    "    up_count = up_down.rolling(window=k).sum()\n",
    "\n",
    "    # Determine the majority class based on the count\n",
    "    k_up_majority = up_count.apply(lambda x: 1 if x >= k / 2 else -1)\n",
    "\n",
    "    return k_up_majority\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ma_kpi(source: str, kind: str, ma_short: pd.Series, ma_long: pd.Series, short_window: int, long_window: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute key performance indicators (KPIs) for moving averages (MA) based on two MA series.\n",
    "    \n",
    "    Args:\n",
    "        source (str): The source of the moving averages (e.g., \"close\", \"volume\").\n",
    "        ma_short (pd.Series): Series containing the short-term MA values.\n",
    "        ma_long (pd.Series): Series containing the long-term MA values.\n",
    "        short_window (int): Window length for the short-term MA.\n",
    "        long_window (int): Window length for the long-term MA.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with MA KPI metrics computed.\n",
    "    \"\"\"\n",
    "    # Initialize an empty DataFrame to store the computed KPIs\n",
    "    kpi_df = pd.DataFrame(index=ma_short.index)\n",
    "    \n",
    "    # Calculate MA crossover signals\n",
    "    golden_cross = np.where((ma_short > ma_long) & (ma_short.shift(1) < ma_long.shift(1)), 1, 0)\n",
    "    death_cross = np.where((ma_short < ma_long) & (ma_short.shift(1) > ma_long.shift(1)), -1, 0)\n",
    "\n",
    "    kpi_df[f'{source}_{kind}_{short_window}_{long_window}_golden_cross_signal_intermediate'] = golden_cross\n",
    "    kpi_df[f'{source}_{kind}_{short_window}_{long_window}_death_cross_signal_intermediate'] = death_cross\n",
    "    \n",
    "    # Combine signals into a single column\n",
    "    signals = np.where(golden_cross == 1, 1, np.where(death_cross == -1, -1, 0))\n",
    "    \n",
    "    # Add computed KPIs to the DataFrame\n",
    "    kpi_df[f'{source}_{kind}_{short_window}_{long_window}_combined_signal'] = signals\n",
    "    \n",
    "    return kpi_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rsi_signals(rsi_series: pd.Series, length: str|int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate boolean signals for overbought/oversold conditions based on RSI indicator.\n",
    "\n",
    "    Args:\n",
    "        rsi_series (pd.Series): Series containing the RSI values.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with boolean signals for buy (entry) and sell (exit) conditions.\n",
    "    \"\"\"\n",
    "    # Initialize DataFrame to store signals\n",
    "    signals_df = pd.DataFrame(index=rsi_series.index)\n",
    "\n",
    "    # Generate signals for RSI: Overbought (> 70) and Oversold (< 30)\n",
    "    signals_df['rsi_overbought'] = np.where(rsi_series > 70, -1, 0)\n",
    "    signals_df['rsi_oversold'] = np.where(rsi_series < 30, 1, 0)\n",
    "\n",
    "    # Combine signals into a single column\n",
    "    signals_df[f\"rsi_{length}_combined_signal\"] = np.where(signals_df['rsi_overbought'] == -1, -1, np.where(signals_df['rsi_oversold'] == 1, 1, 0))\n",
    "\n",
    "    return signals_df\n",
    "\n",
    "\n",
    "def generate_macd_signals(macd_series: pd.Series, macd_signal_series: pd.Series, macd_histogram_series: pd.Series) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate boolean signals for reversal and other metrics based on MACD indicators.\n",
    "\n",
    "    Args:\n",
    "        macd_series (pd.Series): Series containing the MACD Line values.\n",
    "        macd_signal_series (pd.Series): Series containing the MACD Signal Line values.\n",
    "        macd_histogram_series (pd.Series): Series containing the MACD Histogram values.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with boolean signals for reversal and other metrics.\n",
    "    \"\"\"\n",
    "    # Initialize DataFrame to store signals\n",
    "    signals_df = pd.DataFrame(index=macd_series.index)\n",
    "\n",
    "    # Generate signals for MACD Line and Signal Line Crosses\n",
    "    signals_df['macd_cross_above_signal'] = np.where(macd_series > macd_signal_series, 1, 0)\n",
    "    signals_df['macd_cross_below_signal'] = np.where(macd_series < macd_signal_series, -1, 0)\n",
    "    signals_df['macd_signal_cross_combined_signal'] = np.where(signals_df['macd_cross_below_signal'] == -1, -1, np.where(signals_df['macd_cross_above_signal'] == 1, 1, 0))\n",
    "\n",
    "    # Generate signals for MACD Histogram Patterns (Divergences)\n",
    "    signals_df['bullish_divergence'] = np.where((macd_histogram_series > 0) & (macd_histogram_series.shift(1) < 0), 1, 0)\n",
    "    signals_df['bearish_divergence'] = np.where((macd_histogram_series < 0) & (macd_histogram_series.shift(1) > 0), -1, 0)\n",
    "    signals_df['macd_hist_cross_combined_signal'] = np.where(signals_df['bearish_divergence'] == -1, -1, np.where(signals_df['bullish_divergence'] == 1, 1, 0))\n",
    "\n",
    "    # Generate signals for MACD Line and Price Divergence\n",
    "    signals_df['bullish_price_macd_divergence'] = np.where((macd_series > 0) & (macd_series.shift(1) < 0), 1, 0)\n",
    "    signals_df['bearish_price_macd_divergence'] = np.where((macd_series < 0) & (macd_series.shift(1) > 0), -1, 0)\n",
    "    signals_df['macd_divergence_cross_combined_signal'] = np.where(signals_df['bearish_price_macd_divergence'] == -1, -1, np.where(signals_df['bullish_price_macd_divergence'] == 1, 1, 0))\n",
    "\n",
    "    # Generate signals for MACD Line and Signal Line Strength\n",
    "    signals_df['macd_line_strength'] = np.where(macd_series.diff().abs() > 100, 1, 0)\n",
    "    signals_df['macd_signal_strength'] = np.where(macd_signal_series.diff().abs() > 100, 1, 0)\n",
    "\n",
    "    # Generate signals for MACD Line and Signal Line Convergence\n",
    "    signals_df['macd_convergence'] = np.where((macd_series.diff() * macd_signal_series.diff()).shift(1) < 0, 1, 0)\n",
    "\n",
    "    return signals_df\n",
    "\n",
    "def generate_kdj_signals(k_series: pd.Series, d_series: pd.Series, j_series: pd.Series) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate signals based on KDJ indicator values.\n",
    "\n",
    "    Args:\n",
    "        k_series (pd.Series): Series containing the K line values of the KDJ indicator.\n",
    "        d_series (pd.Series): Series containing the D line values of the KDJ indicator.\n",
    "        j_series (pd.Series): Series containing the J line values of the KDJ indicator.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with signals for buy (entry) and sell (exit) conditions.\n",
    "    \"\"\"\n",
    "    # Initialize DataFrame to store signals\n",
    "    signals_df = pd.DataFrame(index=k_series.index)\n",
    "\n",
    "    # Generate signals for KDJ: Buy when K crosses above D and J\n",
    "    signals_df['kdj_buy_signal'] = np.where((k_series > d_series) & (k_series > j_series), 1, 0)\n",
    "\n",
    "    # Generate signals for KDJ: Sell when K crosses below D and J\n",
    "    signals_df['kdj_sell_signal'] = np.where((k_series < d_series) & (k_series < j_series), -1, 0)\n",
    "\n",
    "    # Generate combined signal\n",
    "    signals_df['kdj_combined_signal'] = np.where(signals_df['kdj_sell_signal'] == -1, -1, np.where(signals_df['kdj_buy_signal'] == 1, 1, 0))\n",
    "\n",
    "    return signals_df\n",
    "\n",
    "\n",
    "def generate_vwap_signals(vwap_series: pd.Series, close_series: pd.Series) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate signals based on VWAP (Volume Weighted Average Price).\n",
    "\n",
    "    Args:\n",
    "        vwap_series (pd.Series): Series containing the VWAP values.\n",
    "        close_series (pd.Series): Series containing the closing prices.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with signals for buy (entry) and sell (exit) conditions.\n",
    "    \"\"\"\n",
    "    # Initialize DataFrame to store signals\n",
    "    signals_df = pd.DataFrame(index=close_series.index)\n",
    "\n",
    "    # Generate signals for VWAP: Buy when close price is above VWAP\n",
    "    signals_df['vwap_buy_signal'] = np.where(close_series > vwap_series, 1, 0)\n",
    "\n",
    "    # Generate signals for VWAP: Sell when close price is below VWAP\n",
    "    signals_df['vwap_sell_signal'] = np.where(close_series < vwap_series, -1, 0)\n",
    "\n",
    "    # Generate combined signal\n",
    "    signals_df['vwap_combined_signal'] = np.where(signals_df['vwap_sell_signal'] == -1, -1, np.where(signals_df['vwap_buy_signal'] == 1, 1, 0))\n",
    "\n",
    "    return signals_df\n",
    "\n",
    "\n",
    "def generate_lr_signals(lr_series: pd.Series, close_series: pd.Series) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate signals based on Linear Regression (LR).\n",
    "\n",
    "    Args:\n",
    "        lr_series (pd.Series): Series containing the LR values.\n",
    "        close_series (pd.Series): Series containing the closing prices.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with signals for buy (entry) and sell (exit) conditions.\n",
    "    \"\"\"\n",
    "    # Initialize DataFrame to store signals\n",
    "    signals_df = pd.DataFrame(index=close_series.index)\n",
    "\n",
    "    # Generate signals for LR: Buy when close price is above LR\n",
    "    signals_df['lr_buy_signal'] = np.where(close_series > lr_series, 1, 0)\n",
    "\n",
    "    # Generate signals for LR: Sell when close price is below LR\n",
    "    signals_df['lr_sell_signal'] = np.where(close_series < lr_series, -1, 0)\n",
    "\n",
    "    # Generate combined signal\n",
    "    signals_df['lr_combined_signal'] = np.where(signals_df['lr_sell_signal'] == -1, -1, np.where(signals_df['lr_buy_signal'] == 1, 1, 0))\n",
    "\n",
    "\n",
    "    return signals_df\n",
    "\n",
    "\n",
    "def generate_candlestick_signal(ohlc4_series: pd.Series) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate boolean signals for up and down candlesticks based on OHLC4 (Open, High, Low, Close) values.\n",
    "\n",
    "    Args:\n",
    "        ohlc4_series (pd.Series): Series containing the OHLC4 (Open, High, Low, Close) values.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with boolean signals for up (1) and down (-1) candlesticks.\n",
    "    \"\"\"\n",
    "    # Calculate the difference between Close and Open prices\n",
    "    candlestick_signal = ohlc4_series.diff()\n",
    "\n",
    "    # Generate signal: 1 for up candlestick, -1 for down candlestick\n",
    "    candlestick_signal = np.where(candlestick_signal > 0, 1, -1)\n",
    "\n",
    "    # Create a DataFrame to store the signals\n",
    "    signals_df = pd.DataFrame(index=ohlc4_series.index)\n",
    "    signals_df['candlestick_signal'] = candlestick_signal\n",
    "\n",
    "    return signals_df\n",
    "\n",
    "\n",
    "def generate_adx_signals(adx_series: pd.Series, dmp_series: pd.Series, dmn_series: pd.Series) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate signals for entry and exit based on the ADX (Average Directional Index) indicator.\n",
    "\n",
    "    Args:\n",
    "        adx_series (pd.Series): Series containing the ADX values.\n",
    "        dmp_series (pd.Series): Series containing the DMP (Directional Movement Plus) values.\n",
    "        dmn_series (pd.Series): Series containing the DMN (Directional Movement Minus) values.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with signals for entry and exit conditions.\n",
    "    \"\"\"\n",
    "    # Initialize DataFrame to store signals\n",
    "    signals_df = pd.DataFrame(index=adx_series.index)\n",
    "\n",
    "    # Generate signals for entry when ADX is rising and above a certain threshold\n",
    "    entry_condition = (adx_series > adx_series.shift(1)) & (adx_series > 25)  # Adjust threshold as needed\n",
    "    signals_df['entry_signal'] = np.where(entry_condition, 1, 0)\n",
    "\n",
    "    # Generate signals for exit when ADX is falling below a certain threshold\n",
    "    exit_condition = (adx_series < adx_series.shift(1)) & (adx_series < 20)  # Adjust threshold as needed\n",
    "    signals_df['exit_signal'] = np.where(exit_condition, -1, 0)\n",
    "\n",
    "    # Combine entry and exit signals into a single column\n",
    "    signals_df['combined_signal'] = signals_df['entry_signal'] + signals_df['exit_signal']\n",
    "\n",
    "    # Additional signals (you can customize these):\n",
    "    # 1. DI lines crossover (use dmp_series and dmn_series)\n",
    "    # 2. ADX level (above 20 for entry, below 20 for exit)\n",
    "    # 3. ADX slope (compare ADX with its moving average)\n",
    "\n",
    "    # Example: Add DI lines crossover signal\n",
    "    di_crossover_condition = (dmp_series > dmn_series) & (dmp_series.shift(1) < dmn_series.shift(1))\n",
    "    signals_df['di_crossover_signal'] = np.where(di_crossover_condition, 1, 0)\n",
    "\n",
    "    return signals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if closeprice went bullish or bearish\n",
    "# data = pd.concat([df], axis=1)\n",
    "# data_ = data[[\"close\", \"CDL_INSIDE\"]][\"2022-01\":\"2023-01\"]\n",
    "# # data_ = data[[\"close\", \"CDL_INSIDE\"]]\n",
    "# plot_signals(data_, source_col=\"close\", signal_col=[\"CDL_INSIDE\"])\n",
    "\n",
    "# adx_signals = generate_adx_signals(df.ADX_14, df.DMP_14, df.DMN_14)\n",
    "# # # if closeprice went bullish or bearish\n",
    "# # data = pd.concat([df, adx_signals], axis=1)\n",
    "# # data_ = data[[\"close\", \"combined_signal\"]][\"2021-08\":\"2021-10\"]\n",
    "# # # data_ = data[[\"close\", \"combined_signal\"]]\n",
    "# # plot_signals(data_, source_col=\"close\", signal_col=[\"combined_signal\"])\n",
    "\n",
    "# ohlc4_signal = generate_candlestick_signal(ohlc4_series=df.OHLC4)\n",
    "# ohlc4_signal\n",
    "# # # if closeprice went bullish or bearish\n",
    "# # data = pd.concat([df, ohlc4_signal], axis=1)\n",
    "# # data_ = data[[\"close\", \"candlestick_signal\"]][\"2021-08\":\"2021-10\"]\n",
    "# # # data_ = data[[\"close\", \"candlestick_signal\"]]\n",
    "# # plot_signals(data_, source_col=\"close\", signal_col=[\"candlestick_signal\"])\n",
    "\n",
    "\n",
    "# lr_signals = generate_vwap_signals(vwap_series=df.LR_14, close_series=df.close)\n",
    "# lr_signals\n",
    "\n",
    "# vwap_signals = generate_vwap_signals(vwap_series=df.VWAP_D, close_series=df.close)\n",
    "# # if closeprice went bullish or bearish\n",
    "# data = pd.concat([df, vwap_signals], axis=1)\n",
    "# data_ = data[[\"close\", \"vwap_combined_signal\"]][\"2021-08\":\"2021-10\"]\n",
    "# # data_ = data[[\"close\", \"rsi_14_combined_signal\"]]\n",
    "# plot_signals(data_, source_col=\"close\", signal_col=[\"vwap_combined_signal\"])7\n",
    "\n",
    "\n",
    "# macd_signals = generate_macd_signals(macd_series=df.MACD_12_26_9, macd_histogram_series=df.MACDh_12_26_9, macd_signal_series=df.MACDs_12_26_9)\n",
    "# macd_signals\n",
    "# # if closeprice went bullish or bearish\n",
    "# data = pd.concat([df, macd_signals], axis=1)\n",
    "# data_ = data[[\"close\", \"macd_signal_cross_combined_signal\"]][\"2021-08\":\"2021-10\"]\n",
    "# # data_ = data[[\"close\", \"rsi_14_combined_signal\"]]\n",
    "# plot_signals(data_, source_col=\"close\", signal_col=[\"macd_signal_cross_combined_signal\"])\n",
    "\n",
    "# # if closeprice went bullish or bearish\n",
    "# data = pd.concat([df, macd_signals], axis=1)\n",
    "# data_ = data[[\"close\", \"macd_hist_cross_combined_signal\"]][\"2021-08\":\"2021-10\"]\n",
    "# # data_ = data[[\"close\", \"rsi_14_combined_signal\"]]\n",
    "# plot_signals(data_, source_col=\"close\", signal_col=[\"macd_hist_cross_combined_signal\"])\n",
    "\n",
    "# # if closeprice went bullish or bearish\n",
    "# data = pd.concat([df, macd_signals], axis=1)\n",
    "# data_ = data[[\"close\", \"macd_divergence_cross_combined_signal\"]][\"2021-08\":\"2021-10\"]\n",
    "# # data_ = data[[\"close\", \"rsi_14_combined_signal\"]]\n",
    "# plot_signals(data_, source_col=\"close\", signal_col=[\"macd_divergence_cross_combined_signal\"])\n",
    "\n",
    "# # if closeprice went bullish or bearish\n",
    "# data = pd.concat([df, macd_signals], axis=1)\n",
    "# data_ = data[[\"close\", \"macd_convergence\"]][\"2021-08\":\"2021-10\"]\n",
    "# # data_ = data[[\"close\", \"rsi_14_combined_signal\"]]\n",
    "# plot_signals(data_, source_col=\"close\", signal_col=[\"macd_convergence\"])\n",
    "\n",
    "# # if closeprice went bullish or bearish\n",
    "# data = pd.concat([df, macd_signals], axis=1)\n",
    "# data_ = data[[\"close\", \"macd_signal_strength\"]][\"2021-08\":\"2021-10\"]\n",
    "# # data_ = data[[\"close\", \"rsi_14_combined_signal\"]]\n",
    "# plot_signals(data_, source_col=\"close\", signal_col=[\"macd_signal_strength\"])\n",
    "\n",
    "# # if closeprice went bullish or bearish\n",
    "# data = pd.concat([df, macd_signals], axis=1)\n",
    "# data_ = data[[\"close\", \"macd_line_strength\"]][\"2021-08\":\"2021-10\"]\n",
    "# # data_ = data[[\"close\", \"rsi_14_combined_signal\"]]\n",
    "# plot_signals(data_, source_col=\"close\", signal_col=[\"macd_line_strength\"])\n",
    "\n",
    "# rsi_base_signal = generate_rsi_signals(df.RSI_14, 14)\n",
    "# rsi_base_signal[rsi_base_signal.rsi_14_combined_signal==-1]\n",
    "# # if closeprice went bullish or bearish\n",
    "# data = pd.concat([df, rsi_base_signal], axis=1)\n",
    "# data_ = data[[\"close\", \"rsi_14_combined_signal\"]][\"2021-08\":\"2022-10\"]\n",
    "# # data_ = data[[\"close\", \"rsi_14_combined_signal\"]]\n",
    "# plot_signals(data_, source_col=\"close\", signal_col=[\"rsi_14_combined_signal\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\", \"trades\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Kraken_OHLCVT/ETHUSD_720.csv\", names=column_names, index_col=\"timestamp\")\n",
    "df.index = pd.to_datetime(df.index, unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INDICATORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CustomStrategy = ta.Strategy(\n",
    "    name=\"Trend, Volume, and Momentum Analysis\",\n",
    "    description=\"Calculates SMA, EMA, RSI, MACD, and KDJ for trend, volume, and momentum analysis.\",\n",
    "    ta=[\n",
    "        # Simple Moving Averages (SMA) for close prices\n",
    "        {\"kind\": \"sma\", \"length\": 200, \"prefix\": \"CLOSE\"},\n",
    "        {\"kind\": \"sma\", \"length\": 5, \"prefix\": \"CLOSE\"},\n",
    "        {\"kind\": \"sma\", \"length\": 9, \"prefix\": \"CLOSE\"},\n",
    "        {\"kind\": \"sma\", \"length\": 13, \"prefix\": \"CLOSE\"},\n",
    "        {\"kind\": \"sma\", \"length\": 21, \"prefix\": \"CLOSE\"},\n",
    "        # Exponential Moving Averages (EMA) for close prices\n",
    "        {\"kind\": \"ema\", \"length\": 200, \"prefix\": \"CLOSE\"},\n",
    "        {\"kind\": \"ema\", \"length\": 5, \"prefix\": \"CLOSE\"},\n",
    "        {\"kind\": \"ema\", \"length\": 9, \"prefix\": \"CLOSE\"},\n",
    "        {\"kind\": \"ema\", \"length\": 13, \"prefix\": \"CLOSE\"},\n",
    "        {\"kind\": \"ema\", \"length\": 21, \"prefix\": \"CLOSE\"},\n",
    "        # Simple Moving Averages (SMA) for volume\n",
    "        {\"kind\": \"sma\", \"close\": \"volume\", \"length\": 200, \"prefix\": \"VOLUME\"},\n",
    "        {\"kind\": \"sma\", \"close\": \"volume\", \"length\": 5, \"prefix\": \"VOLUME\"},\n",
    "        {\"kind\": \"sma\", \"close\": \"volume\", \"length\": 9, \"prefix\": \"VOLUME\"},\n",
    "        {\"kind\": \"sma\", \"close\": \"volume\", \"length\": 13, \"prefix\": \"VOLUME\"},\n",
    "        {\"kind\": \"sma\", \"close\": \"volume\", \"length\": 21, \"prefix\": \"VOLUME\"},\n",
    "        # Exponential Moving Averages (EMA) for volume\n",
    "        {\"kind\": \"ema\", \"close\": \"volume\", \"length\": 200, \"prefix\": \"VOLUME\"},\n",
    "        {\"kind\": \"ema\", \"close\": \"volume\", \"length\": 5, \"prefix\": \"VOLUME\"},\n",
    "        {\"kind\": \"ema\", \"close\": \"volume\", \"length\": 9, \"prefix\": \"VOLUME\"},\n",
    "        {\"kind\": \"ema\", \"close\": \"volume\", \"length\": 13, \"prefix\": \"VOLUME\"},\n",
    "        {\"kind\": \"ema\", \"close\": \"volume\", \"length\": 21, \"prefix\": \"VOLUME\"},\n",
    "        # Relative Strength Index (RSI)\n",
    "        {\"kind\": \"rsi\", \"period\": \"14\"},\n",
    "        # Moving Average Convergence Divergence (MACD)\n",
    "        {\"kind\": \"macd\", \"fast\": 12, \"slow\": 26, \"signal\": 9},\n",
    "        # Stochastic Oscillator (KDJ)\n",
    "        # {\"kind\": \"kdj\"},\n",
    "        {\"kind\": \"vwap\"},\n",
    "        {\"kind\": \"linreg\"},\n",
    "        {\"kind\": \"ohlc4\"},\n",
    "        {\"kind\": \"adx\"},\n",
    "        {\"kind\": \"cdl_pattern\"},\n",
    "    ]\n",
    ")\n",
    "# To run your \"Custom Strategy\"\n",
    "df.ta.strategy(CustomStrategy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_kpis = compute_target_variables(df.open, df.high, df.low, df.close, df.volume)\n",
    "df[\"target\"] = target_kpis.close_bullish_bearish_signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STRATEGIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Targets Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_kpis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([df, target_kpis], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if closeprice went bullish or bearish\n",
    "data_ = data[[\"close\", \"close_bullish_bearish_signal\"]][\"2021-08\":\"2021-10\"]\n",
    "# data_ = data[[\"close\", \"close_bullish_bearish_signal\"]]\n",
    "plot_signals(data_, source_col=\"close\", signal_col=[\"close_bullish_bearish_signal\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if volume went bullish or bearish\n",
    "data_ = data[[\"volume\", \"volume_bullish_bearish_signal\"]][\"2021-08\":\"2021-10\"]\n",
    "# data_ = data[[\"volume\", \"volume_bullish_bearish_signal\"]]\n",
    "plot_signals(data_, source_col=\"volume\", signal_col=[\"volume_bullish_bearish_signal\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if higher highers and high lows indications\n",
    "data_ = data[[\"close\", \"price_increase_and_higher_highs_lows_signal\"]][\"2021-08\":\"2021-10\"]\n",
    "# data_ = data[[\"close\", \"price_increase_and_higher_highs_lows_signal\"]]\n",
    "plot_signals(data_, source_col=\"close\", signal_col=[\"price_increase_and_higher_highs_lows_signal\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, target_kpis], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MA Golden, Death & Combined Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MA crossover golden, death and combined signal\n",
    "close_ma_kpis = compute_ma_kpi(source=\"close\", kind=\"sma\", short_window=13, long_window=200, ma_short=df.CLOSE_SMA_13, ma_long=df.CLOSE_SMA_200)\n",
    "close_ma_kpis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, close_ma_kpis], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_ = data[[\"close\", \"CLOSE_SMA_13\", \"CLOSE_SMA_200\", \"close_sma_13_200_combined_signal\"]][\"2021-06\":\"2022-02\"]\n",
    "data_ = data[[\"close\", \"CLOSE_SMA_13\", \"CLOSE_SMA_200\", \"close_sma_13_200_combined_signal\"]]\n",
    "plot_signals(data_, source_col=\"close\", signal_col=[\"close_sma_13_200_combined_signal\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_ = data[[\"close\", \"CLOSE_SMA_13\", \"CLOSE_SMA_200\", \"close_sma_13_200_golden_cross_signal_intermediate\"]][\"2021-06\":\"2022-02\"]\n",
    "data_ = data[[\"close\", \"CLOSE_SMA_13\", \"CLOSE_SMA_200\", \"close_sma_13_200_golden_cross_signal_intermediate\"]]\n",
    "plot_signals(data_, source_col=\"close\", signal_col=[\"close_sma_13_200_golden_cross_signal_intermediate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_ = data[[\"close\", \"CLOSE_SMA_13\", \"CLOSE_SMA_200\", \"close_sma_13_200_death_cross_signal_intermediate\"]][\"2021-06\":\"2022-02\"]\n",
    "data_ = data[[\"close\", \"CLOSE_SMA_13\", \"CLOSE_SMA_200\", \"close_sma_13_200_death_cross_signal_intermediate\"]]\n",
    "plot_signals(data_, source_col=\"close\", signal_col=[\"close_sma_13_200_death_cross_signal_intermediate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K_MAJORITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN-like\n",
    "k=5\n",
    "\n",
    "# past k up candles to classify current\n",
    "df[\"close_k_past_up_majority_signal\"] = calculate_k_majority(df[\"close\"], k)\n",
    "df[\"volume_k_past_up_majority_signal\"] = calculate_k_majority(df[\"volume\"], k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = df[[\"close\", \"close_k_past_up_majority_signal\"]][\"2021-06\":\"2022-02\"]\n",
    "# data_ = df[[\"close\", \"close_k_past_up_majority_signal\"]]\n",
    "plot_signals(data_, source_col=\"close\", signal_col=[\"close_k_past_up_majority_signal\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load OHLCV data with target\n",
    "data = df.copy().dropna()\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into features (X) and target variable (y)\n",
    "X = data.drop(columns=['target'])  # Features\n",
    "y = data['target']  # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the classifier\n",
    "rf_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "import pickle\n",
    "\n",
    "with open('models/random_forest_up_down_classifier_data_720.pkl', 'wb') as f:\n",
    "    pickle.dump(rf_classifier, f)\n",
    "\n",
    "# load model from file \n",
    "# with open('models/random_forest_up_down_classifier.pkl', 'rb') as f:\n",
    "#     rf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the testing set\n",
    "y_pred = rf_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load OHLCV data with target\n",
    "data = df.copy().dropna()\n",
    "data[\"target\"] = np.where(data[\"target\"]==1, 1, 0)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into features (X) and target variable (y)\n",
    "X = data.drop(columns=['target'])  # Features\n",
    "y = data['target']  # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize XGBoost classifier\n",
    "xgb_classifier = xgb.XGBClassifier(objective='binary:logistic', random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the classifier\n",
    "xgb_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "import pickle\n",
    "\n",
    "with open('models/xgb_classifier_up_down_classifier_data_720.pkl', 'wb') as f:\n",
    "    pickle.dump(xgb_classifier, f)\n",
    "\n",
    "# load model from file \n",
    "# with open('models/xgb_classifier_up_down_classifier.pkl', 'rb') as f:\n",
    "#     rf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the testing set\n",
    "y_pred = xgb_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load OHLCV data with target\n",
    "data = df.copy().dropna()\n",
    "data[\"target\"] = np.where(data[\"target\"]==1, 1, 0)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into features (X) and target variable (y)\n",
    "X = data.drop(columns=['target'])  # Features\n",
    "y = data['target']  # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape features for LSTM input (samples, timesteps, features)\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "\n",
    "model.save('models/lstm_up_down_classifier_data_720.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print confusion matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure()\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Bearish', 'Bullish'], yticklabels=['Bearish', 'Bullish'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
